{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d5567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras import Sequential\n",
    "from keras.layers import GRU, Embedding, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29712ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import train\n",
    "train = pd.read_csv('train.csv')\n",
    "train = train.replace(np.nan, '', regex=True)\n",
    "#import test\n",
    "test = pd.read_csv('test.csv')\n",
    "#import sample submission\n",
    "samp = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4029f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA\n",
    "print(train.info())\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576278df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instances By Class\n",
    "train['target'].value_counts().plot(kind = 'bar', color = ['blue', 'orange'])\n",
    "plt.title('Instances by Class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Instances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charts for null values in keyword and location by class\n",
    "plt.subplot(1, 2, 1)\n",
    "train['target'][train['keyword'] == ''].value_counts().plot(kind = 'bar', color = ['orange', 'blue'])\n",
    "plt.title('Keyword Null Values by Class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Keyword Null Values')\n",
    "plt.subplot(1, 2, 2)\n",
    "train['target'][train['location'] == ''].value_counts().plot(kind = 'bar', color = ['blue', 'orange'])\n",
    "plt.title('Location Null Values by Class')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Location Null Values')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Data Preprocessing\n",
    "#removing what is not word sentence or number in text \n",
    "train['text'] = train['text'].str.replace(r'[^\\w\\s]+', '', regex = True)\n",
    "#removing URLs\n",
    "train['text'] = train['text'].str.replace(r'https?://(www\\.)?(\\w+)(\\.\\w+)(/\\w*)?', '', regex = True)\n",
    "#removing words with numbers\n",
    "train['text'] = train['text'].str.replace(r'\\w*\\d\\w*', '', regex= True)\n",
    "\n",
    "#making all words lowercase\n",
    "train['text'] = train['text'].apply(lambda x: x.lower())\n",
    "\n",
    "#removing html tags with Beautiful Soup\n",
    "def html_remove(x):\n",
    "    return BeautifulSoup(x, 'lxml').get_text()\n",
    "train['text'] = train['text'].apply(lambda x: html_remove(x))\n",
    "\n",
    "#Removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens_no_stop = [i for i in tokens if i not in stop_words]\n",
    "    tokens_filtered = (' ').join(tokens_no_stop)\n",
    "    return tokens_filtered\n",
    "train['text'] = train['text'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing Text train data\n",
    "#source: https://medium.datadriveninvestor.com/padding-used-in-nlp-are-they-improvers-2f4613bd3648\n",
    "tokenizer = Tokenizer(num_words = 5000)\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(list(word_index.keys())) + 1\n",
    "sequences = tokenizer.texts_to_sequences(train['text'])\n",
    "padded_sequences = pad_sequences(sequences, padding='post', truncating='post', maxlen=vocab_size)\n",
    "# print(padded_sequences)\n",
    "\n",
    "\n",
    "#Tokenizing Text test\n",
    "sequences_test = tokenizer.texts_to_sequences(test['text'])\n",
    "padded_sequences_test = pad_sequences(sequences_test, padding='post', truncating='post', maxlen=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(padded_sequences.shape)\n",
    "print(padded_sequences_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc163350",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(word_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7edbf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting X and y\n",
    "X = train['text']\n",
    "y = train['target']\n",
    "#splitting into training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7801541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TFIDF for Train data\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# vector_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# #TFIDF for Valid data\n",
    "# vector_tfidf_test = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# #Vocabulary\n",
    "# vocabulary = np.array(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a019df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(list(word_index.keys())) + 1\n",
    "#model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 128, input_length=padded_sequences.shape[1]),\n",
    "    GRU(64),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "# ROC = AUC()\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f606931",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(patience = 3)\n",
    "model.fit(\n",
    "    padded_sequences, \n",
    "    y, \n",
    "    validation_split=0.2, \n",
    "    epochs = 30, \n",
    "    batch_size=256,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test Data\n",
    "\n",
    "##Data Preprocessing\n",
    "#removing what is not word sentence or number in text \n",
    "test['text'] = test['text'].str.replace(r'[^\\w\\s]+', '', regex = True)\n",
    "#removing URLs\n",
    "test['text'] = test['text'].str.replace(r'https?://(www\\.)?(\\w+)(\\.\\w+)(/\\w*)?', '', regex = True)\n",
    "#removing words with numbers\n",
    "test['text'] = test['text'].str.replace(r'\\w*\\d\\w*', '', regex= True)\n",
    "\n",
    "#making all words lowercase\n",
    "test['text'] = test['text'].apply(lambda x: x.lower())\n",
    "\n",
    "#removing html tags with Beautiful Soup\n",
    "def html_remove(x):\n",
    "    return BeautifulSoup(x, 'lxml').get_text()\n",
    "test['text'] = test['text'].apply(lambda x: html_remove(x))\n",
    "\n",
    "#Removing stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens_no_stop = [i for i in tokens if i not in stop_words]\n",
    "    tokens_filtered = (' ').join(tokens_no_stop)\n",
    "    return tokens_filtered\n",
    "test['text'] = test['text'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3385584",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34027c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(padded_sequences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f28a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
